{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "90aac2da-f8b6-469c-a7a0-571a82cd8c6a",
   "metadata": {},
   "source": [
    "## Project Purpose\n",
    "Developing a Sentiment Analysis project where the ups and downs of Twitter sentiment are tracked for a pet related company.\n",
    "\n",
    "The motivation for this analysis is to help a company see what topics or other factors might correlate with better or worse sentiment towards a company\n",
    "\n",
    "Most of the code for pulling the Twitter data was gleaned from Samantha Jone's article on Tweepy: https://www.linkedin.com/pulse/extracting-tweet-information-tweepy-beautifulsoup-samantha-jones/###\n",
    "\n",
    "Samantha Jones: https://www.linkedin.com/in/samanthaaldene/ \n",
    "\n",
    "The Tweepy site is self is here: https://www.tweepy.org/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ebab246-5599-45e7-803f-5895c629fd73",
   "metadata": {},
   "source": [
    "## Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c6369634-82a3-49ca-98a2-7925e1426b3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tweepy\n",
    "from tweepy import OAuthHandler\n",
    "import requests\n",
    "from tqdm import tqdm\n",
    "from bs4 import BeautifulSoup as bs\n",
    "from urllib.parse import urljoin, urlparse\n",
    "from requests_oauthlib import OAuth1\n",
    "from cleantext import clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "826a8815-ee1e-4320-9fad-bb895ff8a65a",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RT @nicolaiarips: I literally keep pitching about these girls and nobody BITES. I‚Äôm sick of it. I‚Äôm obsessed with them I want to write abou‚Ä¶\n",
      "RT @tetisheri: Recruiting for a Study: Are you a UX professional? We at UC Santa Cruz are doing a small remote research study to understand‚Ä¶\n",
      "RT @Zochrot: Here's why we encourage cities across the world to follow Barcelona historical move &amp; end their twinning agreements with #Isra‚Ä¶\n",
      "RT @BrightonBDS: #Barcelona has cut twinning ties with Tel Aviv.\n",
      "Maybe these UK councils can now follow suit:\n",
      "@BCPCouncil &gt; Netanya.\n",
      "@Newca‚Ä¶\n",
      "RT @steketeh: Barcelona Mayor announces suspension of the city's relations with Israel incl twinning with Tel Aviv. In the face of aparthei‚Ä¶\n",
      "I have seen more shit (literally) on the sidewalk in 6 months living here than in 10 years in New York\n",
      "Wild how cancelling some topic on my syllabus in order to make extra time for us to practice what we've already bee‚Ä¶ https://t.co/au1LPVNKGu\n",
      "When I see a door-to-door salesman walking from the neighbor house over to mine, and I suddenly have to leave my li‚Ä¶ https://t.co/vRA7LL1Pm0\n",
      "RT @TVietor08: This is an amazing story. When a Twitter employee (politely) told @elonmusk that his view count was down because people are‚Ä¶\n",
      "RT @waDNR: Twitter‚Äôs down, time to admit our foresters are just a couple of beavers wearing flannel\n",
      "RT @09mshatraw: @InternetHippo \"Buy one, get one free!\" Oh yeah? Buy zero, keep my money.\n",
      "RT @InternetHippo: Sales tactics don't work on me because I don't actually want to buy anything. \"This deal won't last!\" Damn that's crazy\n",
      "RT @ekymutualaid: a little of what we accomplished yesterday. the community fund has $14 in it. we need to feed people today. to make sure‚Ä¶\n",
      "The best part about putting your speeches up as blog posts later is that you can add a paragraph or two of stuff yo‚Ä¶ https://t.co/vouWE4xwk4\n",
      "What do you hope people know about linguistics in 30 years?\n",
      "Who do you want to reach?\n",
      "Where are they?\n",
      "What do they‚Ä¶ https://t.co/BSPMhDN8bG\n",
      "RT @Emily_Benn: I‚Äôve just had of those train journeys you‚Äôre never going to forget\n",
      "\n",
      "The guy next to us starts talking. He says  he wants to‚Ä¶\n",
      "Don‚Äôt give the WV legislature ideas. https://t.co/4n6woZZ43I\n",
      "FYI: Pay people.\n",
      "\n",
      "Just because you're a co-author, doesn't mean you can eat.  Money, pay people money.\n",
      "W√§re jetzt dann bereit f√ºr eine Runde in der https://t.co/LBm0zxxBFd\n"
     ]
    }
   ],
   "source": [
    "#Handle Twitter API authentication; produces a json file\n",
    "\n",
    "consumer_key = \"s2RQHHhTBhg7rmGP2r8K9bKmZ\"\n",
    "consumer_secret = \"BNspDCtvyIIWSfSaZ3sWVDE82JSqVAoel4oxiD7rjiKhHCq1rZ\"\n",
    "access_token = \"4243232613-GfIElLNDpFCVWUlMqMU6ZGSah9uVfJZJ6W1AeCR\"\n",
    "access_token_secret = \"rURKXxsocX8ivZVEVugOG0Y8ti9VTIS2nzUAVztCWSI9s\"\n",
    " \n",
    "auth = tweepy.OAuth1UserHandler(\n",
    "   consumer_key, consumer_secret, access_token, access_token_secret\n",
    ")\n",
    "\n",
    "api = tweepy.API(auth)\n",
    "\n",
    "###testing out the api connection\n",
    "public_tweets = api.home_timeline()\n",
    "for tweet in public_tweets:\n",
    "    print(tweet.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "3864614d-eac4-4085-8434-638f252105c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Tweets Extracted: 200.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "userID = \"Purina\"\n",
    "tweets_purina = api.user_timeline(screen_name=userID, \n",
    "                           count=200,\n",
    "                           include_rts = False)\n",
    "print(\"Number of Tweets Extracted: {}.\\n\".format(len(tweets)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "4b61e265-0793-409e-aa09-7d0d1b2e01a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Tweets Extracted: 200.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "userID = \"DiamondPetFood\"\n",
    "tweets_diamond = api.user_timeline(screen_name=userID, \n",
    "                           count=200,\n",
    "                           include_rts = False)\n",
    "print(\"Number of Tweets Extracted: {}.\\n\".format(len(tweets)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "1dec37fe-f113-46eb-acef-369c24927aa7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Tweets Extracted: 200.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "userID = \"wellnesspetfood\"\n",
    "tweets_wellness = api.user_timeline(screen_name=userID, \n",
    "                           count=200,\n",
    "                           include_rts = False)\n",
    "print(\"Number of Tweets Extracted: {}.\\n\".format(len(tweets)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "03409fdc-056f-48b0-bb93-99178006e641",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Tweets Extracted: 200.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "userID = \"bluebuffalo\"\n",
    "tweets_bluebuffalo = api.user_timeline(screen_name=userID, \n",
    "                           count=200,\n",
    "                           include_rts = False)\n",
    "print(\"Number of Tweets Extracted: {}.\\n\".format(len(tweets)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "5b5b163f-e6e8-4bcf-89da-49f5ae5591c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "@AlonsoOg Thank you for making us aware of this. We‚Äôre sorry to see this, and we are committed to making this right‚Ä¶ https://t.co/P6qJQOGArk\n",
      "@MonicaEli04 Max, ofc u qualify üòçüòç\n",
      "@murphy_the_gr8 Oughe !\n",
      "@GingerLoafTigs @sarge_the_kitty @benny_the_kitty yeah. . . Friends\n",
      "@Skullcattery22 Lizzy, patiently waiting....üòç\n"
     ]
    }
   ],
   "source": [
    "#simple overview to make sure that it pulls correctly...And it looks good\n",
    "for tweet in tweets_bluebuffalo[:5]:\n",
    "    print(tweet.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "0e76ac3d-8b0b-4a14-982c-65118b762043",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 199 entries, 0 to 198\n",
      "Data columns (total 4 columns):\n",
      " #   Column        Non-Null Count  Dtype              \n",
      "---  ------        --------------  -----              \n",
      " 0   Tweet_Length  199 non-null    int64              \n",
      " 1   Tweet_Text    199 non-null    object             \n",
      " 2   Tweet_Date    199 non-null    datetime64[ns, UTC]\n",
      " 3   UserName      199 non-null    object             \n",
      "dtypes: datetime64[ns, UTC](1), int64(1), object(2)\n",
      "memory usage: 6.3+ KB\n"
     ]
    }
   ],
   "source": [
    "#create dataframe to house data.\n",
    "purina_df = pd.DataFrame(data=[[len(tweet.text), tweet.text, tweet.created_at, tweet.user.screen_name] for tweet in tweets_purina], \n",
    "                         columns = ['Tweet_Length', 'Tweet_Text', 'Tweet_Date', 'UserName'])\n",
    "purina_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "5b094d6b-2e14-4c82-b49a-6db59c3311c1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 199 entries, 0 to 198\n",
      "Data columns (total 4 columns):\n",
      " #   Column        Non-Null Count  Dtype              \n",
      "---  ------        --------------  -----              \n",
      " 0   Tweet_Length  199 non-null    int64              \n",
      " 1   Tweet_Text    199 non-null    object             \n",
      " 2   Tweet_Date    199 non-null    datetime64[ns, UTC]\n",
      " 3   UserName      199 non-null    object             \n",
      "dtypes: datetime64[ns, UTC](1), int64(1), object(2)\n",
      "memory usage: 6.3+ KB\n"
     ]
    }
   ],
   "source": [
    "wellness_df = pd.DataFrame(data=[[len(tweet.text), tweet.text, tweet.created_at, tweet.user.screen_name] for tweet in tweets_wellness], \n",
    "                           columns = ['Tweet_Length', 'Tweet_Text', 'Tweet_Date', 'UserName'])\n",
    "wellness_df.info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "5661d99f-21aa-4e7b-8488-9658508da818",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 200 entries, 0 to 199\n",
      "Data columns (total 4 columns):\n",
      " #   Column        Non-Null Count  Dtype              \n",
      "---  ------        --------------  -----              \n",
      " 0   Tweet_Length  200 non-null    int64              \n",
      " 1   Tweet_Text    200 non-null    object             \n",
      " 2   Tweet_Date    200 non-null    datetime64[ns, UTC]\n",
      " 3   UserName      200 non-null    object             \n",
      "dtypes: datetime64[ns, UTC](1), int64(1), object(2)\n",
      "memory usage: 6.4+ KB\n"
     ]
    }
   ],
   "source": [
    "bluebuffalo_df = pd.DataFrame(data=[[len(tweet.text), tweet.text, tweet.created_at, tweet.user.screen_name] for tweet in tweets_bluebuffalo], \n",
    "                              columns = ['Tweet_Length', 'Tweet_Text', 'Tweet_Date', 'UserName'])\n",
    "bluebuffalo_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "a718550e-e1ac-425c-878b-82a6de04ad38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 200 entries, 0 to 199\n",
      "Data columns (total 4 columns):\n",
      " #   Column        Non-Null Count  Dtype              \n",
      "---  ------        --------------  -----              \n",
      " 0   Tweet_Length  200 non-null    int64              \n",
      " 1   Tweet_Text    200 non-null    object             \n",
      " 2   Tweet_Date    200 non-null    datetime64[ns, UTC]\n",
      " 3   UserName      200 non-null    object             \n",
      "dtypes: datetime64[ns, UTC](1), int64(1), object(2)\n",
      "memory usage: 6.4+ KB\n"
     ]
    }
   ],
   "source": [
    "diamond_df = pd.DataFrame(data=[[len(tweet.text), tweet.text, tweet.created_at, tweet.user.screen_name] for tweet in tweets_diamond], \n",
    "                          columns = ['Tweet_Length', 'Tweet_Text', 'Tweet_Date', 'UserName'])\n",
    "diamond_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f803b928-db1a-4d96-900d-06331a9c27e2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4fb9dc37-807e-4896-8d84-0c59d282e6cf",
   "metadata": {},
   "source": [
    "With four different dataframes, the question is how these four companies compare in terms of sentiment analysis.\n",
    "\n",
    "Let's first take a look at combining and cleaning these datasets, preparing them for NLP analysis:\n",
    "\n",
    "Will I want a separate column for those accounts tagged?\n",
    "How about emoji usage? Should I count those and the accounts tagged and have them as intergers to see if I can run an ML model on the percent sentiment? Can you do an ML model on percent or do I need to convert to 1 for over 50% and 0 for under?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "bbe5401f-bac2-4783-877b-079969fd04ae",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 798 entries, 0 to 199\n",
      "Data columns (total 4 columns):\n",
      " #   Column        Non-Null Count  Dtype              \n",
      "---  ------        --------------  -----              \n",
      " 0   Tweet_Length  798 non-null    int64              \n",
      " 1   Tweet_Text    798 non-null    object             \n",
      " 2   Tweet_Date    798 non-null    datetime64[ns, UTC]\n",
      " 3   UserName      798 non-null    object             \n",
      "dtypes: datetime64[ns, UTC](1), int64(1), object(2)\n",
      "memory usage: 31.2+ KB\n"
     ]
    }
   ],
   "source": [
    "frames = [purina_df, wellness_df, bluebuffalo_df, diamond_df]\n",
    "df = pd.concat(frames)\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "f4de361e-68f1-472e-94ba-8a0834d8fe1c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "bluebuffalo        200\n",
       "DiamondPetFood     200\n",
       "Purina             199\n",
       "wellnesspetfood    199\n",
       "Name: UserName, dtype: int64"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['UserName'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "7b48c3f4-1e94-46f0-99f1-05a5ea6b6075",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_colwidth', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "88d91c9f-613b-4582-a6c2-621bbc86a8e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                      Daisy would like you to tell her she's a good girl. Don't worry, she'll wait. ‚ò∫Ô∏è \\n\\nüì∏: Spencer C. https://t.co/dUNZnvlVCI\n",
       "1                                                     Reply and let us know what your pet's favorite love language is! ‚ù§Ô∏è https://t.co/aL9AeCFyXL\n",
       "2                                                 @TerriHorat Hi Terri! That's PAWsome! Thanks so much for being a loyal Diamond Pet Foods fan! ü§©\n",
       "3                                                           @GreenMo72429984 Raise the woof! Thank you for being a loyal Diamond Pet Foods fan! üêæ\n",
       "4                                       @AvonStaceys Hi Stacey! We‚Äôre so fur-tunate! üêæ Thanks to you and your pup for choosing Diamond Pet Foods!\n",
       "5                                                           POV: The dentist just told you to \"open wide.\"\\n\\nüì∏: Janna C. https://t.co/Oy9cvOkdCp\n",
       "6    If you find that your pet is sleeping the day away even more than usual, there might be a reason. Check out our blo‚Ä¶ https://t.co/cXRfPYMgwL\n",
       "7                                                     @TrevorrowRobert We can't speak to Hondo's exact breed, but we think that's a good guess! üêæ\n",
       "8            Could intestinal parasites be contributing to your pet's sensitive stomach? Check out our blog to find out!‚Ä¶ https://t.co/btkanMDjBE\n",
       "9                                                                                          @BookerBetzaida She is looking quite fetching today! üòç\n",
       "Name: Tweet_Text, dtype: object"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Let's take a look at some sample tweets to see what is possible here:\n",
    "df['Tweet_Text'][:10]\n",
    "### Might be useful to count how many times each tweet responds or @ some other user; Also that \"Please\" that Purina keeps\n",
    "### throwing out there . . . yikes. That kind of discourse marker is something to watch for."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce271348-f688-4a93-8c38-821b98d1eba9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_trim = df\n",
    "df_trim = df['Tweet_Text'].str.split(\"http\", n=1, expand=True)\n",
    "df_trim[1] = 'http' + df_trim[1].astype(str)\n",
    "df_trim.columns = [\"Full_Tweets\", \"Tweet_Links\"]\n",
    "df_trim[\"Tweet_Links\"]=df_trim['Tweet_Links'].str.split().str[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8c6f634-70c3-4fd2-9d6d-94b56fa39aed",
   "metadata": {},
   "source": [
    "Separating out mentions in order to count them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "df12c4e9-fd64-45e5-a01f-248011fd829d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_at_word(text):\n",
    "    word=re.findall(r'(?<=@)\\w+',text)\n",
    "    return \" \".join(word)\n",
    "\n",
    "df_trim['at_word']=df_trim['Full_Tweets'].apply(lambda x: find_at_word(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "3fd1cd7c-ddee-4231-8883-78386185f012",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Full_Tweets</th>\n",
       "      <th>Tweet_Links</th>\n",
       "      <th>at_word</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>@lhartness Thank you for reaching out. We‚Äôre sorry that we are experiencing some technical difficulties and our ded‚Ä¶</td>\n",
       "      <td>https://t.co/k5ncW6PGIU</td>\n",
       "      <td>lhartness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@fireshadowed Thank you for reaching out. We‚Äôre sorry that we are experiencing some technical difficulties and our‚Ä¶</td>\n",
       "      <td>https://t.co/tABQff7epw</td>\n",
       "      <td>fireshadowed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@BonnieblueBlue Thank you for reaching out to us.  When you have a chance, please send us a private message with th‚Ä¶</td>\n",
       "      <td>https://t.co/GMsyUvy5Oq</td>\n",
       "      <td>BonnieblueBlue</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                             Full_Tweets  \\\n",
       "0  @lhartness Thank you for reaching out. We‚Äôre sorry that we are experiencing some technical difficulties and our ded‚Ä¶    \n",
       "1   @fireshadowed Thank you for reaching out. We‚Äôre sorry that we are experiencing some technical difficulties and our‚Ä¶    \n",
       "2  @BonnieblueBlue Thank you for reaching out to us.  When you have a chance, please send us a private message with th‚Ä¶    \n",
       "\n",
       "               Tweet_Links         at_word  \n",
       "0  https://t.co/k5ncW6PGIU       lhartness  \n",
       "1  https://t.co/tABQff7epw    fireshadowed  \n",
       "2  https://t.co/GMsyUvy5Oq  BonnieblueBlue  "
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_trim.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "id": "29eb1390-8cc4-4042-8de1-67ac7ed31584",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 798 entries, 0 to 199\n",
      "Data columns (total 6 columns):\n",
      " #   Column        Non-Null Count  Dtype              \n",
      "---  ------        --------------  -----              \n",
      " 0   Tweet_Length  798 non-null    int64              \n",
      " 1   Tweet_Date    798 non-null    datetime64[ns, UTC]\n",
      " 2   UserName      798 non-null    object             \n",
      " 3   Full_Tweets   798 non-null    object             \n",
      " 4   Tweet_Links   798 non-null    object             \n",
      " 5   at_word       798 non-null    object             \n",
      "dtypes: datetime64[ns, UTC](1), int64(1), object(4)\n",
      "memory usage: 43.6+ KB\n"
     ]
    }
   ],
   "source": [
    "frames = [df, df_trim]\n",
    "df_new = pd.concat(frames, axis=1)\n",
    "df_new = df_new.drop(columns = 'Tweet_Text')\n",
    "df_new.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "a33b9f67-a739-4dd1-b4e9-4b5ec7e80e5a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "bluebuffalo        200\n",
       "DiamondPetFood     200\n",
       "Purina             199\n",
       "wellnesspetfood    199\n",
       "Name: UserName, dtype: int64"
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_new['UserName'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "f7e88633-40f2-47d7-b09c-197c4db96726",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new['Full_Tweets'] = df_new['Full_Tweets'].apply(str.lower)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "635ad6cc-101c-4450-b214-8afb2bc61903",
   "metadata": {},
   "source": [
    "Expanding contractions here using: https://towardsdatascience.com/a-practitioners-guide-to-natural-language-processing-part-i-processing-understanding-text-9f4abfd13e72"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "275c9728-c9c8-471b-90ad-0bd54607b84a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Created on Mon Aug 01 01:11:02 2016\n",
    "\n",
    "@author: DIP\n",
    "\"\"\"\n",
    "\n",
    "CONTRACTION_MAP = {\n",
    "\"ain't\": \"is not\",\n",
    "\"aren't\": \"are not\",\n",
    "\"can't\": \"cannot\",\n",
    "\"can't've\": \"cannot have\",\n",
    "\"'cause\": \"because\",\n",
    "\"could've\": \"could have\",\n",
    "\"couldn't\": \"could not\",\n",
    "\"couldn't've\": \"could not have\",\n",
    "\"didn't\": \"did not\",\n",
    "\"doesn't\": \"does not\",\n",
    "\"don't\": \"do not\",\n",
    "\"hadn't\": \"had not\",\n",
    "\"hadn't've\": \"had not have\",\n",
    "\"hasn't\": \"has not\",\n",
    "\"haven't\": \"have not\",\n",
    "\"he'd\": \"he would\",\n",
    "\"he'd've\": \"he would have\",\n",
    "\"he'll\": \"he will\",\n",
    "\"he'll've\": \"he he will have\",\n",
    "\"he's\": \"he is\",\n",
    "\"how'd\": \"how did\",\n",
    "\"how'd'y\": \"how do you\",\n",
    "\"how'll\": \"how will\",\n",
    "\"how's\": \"how is\",\n",
    "\"I'd\": \"I would\",\n",
    "\"I'd've\": \"I would have\",\n",
    "\"I'll\": \"I will\",\n",
    "\"I'll've\": \"I will have\",\n",
    "\"I'm\": \"I am\",\n",
    "\"I've\": \"I have\",\n",
    "\"i'd\": \"i would\",\n",
    "\"i'd've\": \"i would have\",\n",
    "\"i'll\": \"i will\",\n",
    "\"i'll've\": \"i will have\",\n",
    "\"i'm\": \"i am\",\n",
    "\"i've\": \"i have\",\n",
    "\"isn't\": \"is not\",\n",
    "\"it'd\": \"it would\",\n",
    "\"it'd've\": \"it would have\",\n",
    "\"it'll\": \"it will\",\n",
    "\"it'll've\": \"it will have\",\n",
    "\"it's\": \"it is\",\n",
    "\"let's\": \"let us\",\n",
    "\"ma'am\": \"madam\",\n",
    "\"mayn't\": \"may not\",\n",
    "\"might've\": \"might have\",\n",
    "\"mightn't\": \"might not\",\n",
    "\"mightn't've\": \"might not have\",\n",
    "\"must've\": \"must have\",\n",
    "\"mustn't\": \"must not\",\n",
    "\"mustn't've\": \"must not have\",\n",
    "\"needn't\": \"need not\",\n",
    "\"needn't've\": \"need not have\",\n",
    "\"o'clock\": \"of the clock\",\n",
    "\"oughtn't\": \"ought not\",\n",
    "\"oughtn't've\": \"ought not have\",\n",
    "\"shan't\": \"shall not\",\n",
    "\"sha'n't\": \"shall not\",\n",
    "\"shan't've\": \"shall not have\",\n",
    "\"she'd\": \"she would\",\n",
    "\"she'd've\": \"she would have\",\n",
    "\"she'll\": \"she will\",\n",
    "\"she'll've\": \"she will have\",\n",
    "\"she's\": \"she is\",\n",
    "\"should've\": \"should have\",\n",
    "\"shouldn't\": \"should not\",\n",
    "\"shouldn't've\": \"should not have\",\n",
    "\"so've\": \"so have\",\n",
    "\"so's\": \"so as\",\n",
    "\"that'd\": \"that would\",\n",
    "\"that'd've\": \"that would have\",\n",
    "\"that's\": \"that is\",\n",
    "\"there'd\": \"there would\",\n",
    "\"there'd've\": \"there would have\",\n",
    "\"there's\": \"there is\",\n",
    "\"they'd\": \"they would\",\n",
    "\"they'd've\": \"they would have\",\n",
    "\"they'll\": \"they will\",\n",
    "\"they'll've\": \"they will have\",\n",
    "\"they're\": \"they are\",\n",
    "\"they've\": \"they have\",\n",
    "\"to've\": \"to have\",\n",
    "\"wasn't\": \"was not\",\n",
    "\"we'd\": \"we would\",\n",
    "\"we'd've\": \"we would have\",\n",
    "\"we'll\": \"we will\",\n",
    "\"we'll've\": \"we will have\",\n",
    "\"we're\": \"we are\",\n",
    "\"we've\": \"we have\",\n",
    "\"weren't\": \"were not\",\n",
    "\"what'll\": \"what will\",\n",
    "\"what'll've\": \"what will have\",\n",
    "\"what're\": \"what are\",\n",
    "\"what's\": \"what is\",\n",
    "\"what've\": \"what have\",\n",
    "\"when's\": \"when is\",\n",
    "\"when've\": \"when have\",\n",
    "\"where'd\": \"where did\",\n",
    "\"where's\": \"where is\",\n",
    "\"where've\": \"where have\",\n",
    "\"who'll\": \"who will\",\n",
    "\"who'll've\": \"who will have\",\n",
    "\"who's\": \"who is\",\n",
    "\"who've\": \"who have\",\n",
    "\"why's\": \"why is\",\n",
    "\"why've\": \"why have\",\n",
    "\"will've\": \"will have\",\n",
    "\"won't\": \"will not\",\n",
    "\"won't've\": \"will not have\",\n",
    "\"would've\": \"would have\",\n",
    "\"wouldn't\": \"would not\",\n",
    "\"wouldn't've\": \"would not have\",\n",
    "\"y'all\": \"you all\",\n",
    "\"y'all'd\": \"you all would\",\n",
    "\"y'all'd've\": \"you all would have\",\n",
    "\"y'all're\": \"you all are\",\n",
    "\"y'all've\": \"you all have\",\n",
    "\"you'd\": \"you would\",\n",
    "\"you'd've\": \"you would have\",\n",
    "\"you'll\": \"you will\",\n",
    "\"you'll've\": \"you will have\",\n",
    "\"you're\": \"you are\",\n",
    "\"you've\": \"you have\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "852631b9-0c81-4e62-ab2a-3ccb3b86c903",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'You all cannot expand contractions I would think'"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Pulling from DJ Sarkar, cited above\n",
    "\n",
    "def expand_contractions(text, contraction_mapping=CONTRACTION_MAP):\n",
    "    \n",
    "    contractions_pattern = re.compile('({})'.format('|'.join(contraction_mapping.keys())), \n",
    "                                      flags=re.IGNORECASE|re.DOTALL)\n",
    "    def expand_match(contraction):\n",
    "        match = contraction.group(0)\n",
    "        first_char = match[0]\n",
    "        expanded_contraction = contraction_mapping.get(match)\\\n",
    "                                if contraction_mapping.get(match)\\\n",
    "                                else contraction_mapping.get(match.lower())                       \n",
    "        expanded_contraction = first_char+expanded_contraction[1:]\n",
    "        return expanded_contraction\n",
    "        \n",
    "    expanded_text = contractions_pattern.sub(expand_match, text)\n",
    "    expanded_text = re.sub(\"'\", \"\", expanded_text)\n",
    "    return expanded_text\n",
    "\n",
    "expand_contractions(\"Y'all can't expand contractions I'd think\")\n",
    "# So that works nicely, now to apply it to the full tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "276730f2-719e-4a95-87b9-d1abff7354e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new['Full_Tweets'] = df_new['Full_Tweets'].apply(lambda x: expand_contractions(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "8faebaca-8f9e-4088-ab11-64f055e794f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "197    \"sorry, i have plans.\"\\n\\nthe plans:\\n- petting my dog\\n- playing with my dog\\n- cuddling with my dog\n",
       "198                               hermes loves dates at the dog park! üêï üå≥ üçÇ anybody else?\\n\\nüì∏: corrinne k. \n",
       "199                                                \"where did all of these cardboard boxes come from?!\" üò∏ üì¶ \n",
       "Name: Full_Tweets, dtype: object"
      ]
     },
     "execution_count": 213,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_new['Full_Tweets'].tail(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3eb045e6-860d-4f57-9c05-3c77a8f7b420",
   "metadata": {},
   "source": [
    "Removing emoji's using clean from clean-text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "4cc9b731-a563-4b8f-a9a3-193e12ff6528",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "this sample text contains laughing emojis\n"
     ]
    }
   ],
   "source": [
    "#provide string with emojis\n",
    "text = \"This sample text contains laughing emojis üòÄ üòÉ üòÑ üòÅ üòÜ üòÖ üòÇ ü§£\"\n",
    "\n",
    "#print text after removing the emojis from it\n",
    "print(clean(text, no_emoji=True))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "08546ae4-533e-4b8a-a453-ebe6ae6765da",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new['Full_Tweets'] = df_new['Full_Tweets'].apply(lambda x: (clean(x, no_emoji=True)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "id": "d783f9d1-97a5-4c3a-a2fa-5b222c1c6d03",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Removing the mentions themselves from the Full_Tweets column; already separated off\n",
    "\n",
    "df_new['Full_Tweets'] = df_new['Full_Tweets'].apply(lambda x: re.sub(\"@[A-Za-z0-9_]+\",\"\", x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "id": "744d8b50-2036-47e4-9f2f-3bd136197f3d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tweet_Length</th>\n",
       "      <th>Tweet_Date</th>\n",
       "      <th>UserName</th>\n",
       "      <th>Full_Tweets</th>\n",
       "      <th>Tweet_Links</th>\n",
       "      <th>at_word</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>140</td>\n",
       "      <td>2023-02-09 19:42:43+00:00</td>\n",
       "      <td>Purina</td>\n",
       "      <td>thank you for reaching out. we're sorry that we are experiencing some technical difficulties and our ded</td>\n",
       "      <td>https://t.co/k5ncW6PGIU</td>\n",
       "      <td>lhartness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>139</td>\n",
       "      <td>2023-02-09 19:41:43+00:00</td>\n",
       "      <td>Purina</td>\n",
       "      <td>thank you for reaching out. we're sorry that we are experiencing some technical difficulties and our</td>\n",
       "      <td>https://t.co/tABQff7epw</td>\n",
       "      <td>fireshadowed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>140</td>\n",
       "      <td>2023-02-09 16:09:53+00:00</td>\n",
       "      <td>Purina</td>\n",
       "      <td>thank you for reaching out to us. when you have a chance, please send us a private message with th</td>\n",
       "      <td>https://t.co/GMsyUvy5Oq</td>\n",
       "      <td>BonnieblueBlue</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Tweet_Length                Tweet_Date UserName  \\\n",
       "0           140 2023-02-09 19:42:43+00:00   Purina   \n",
       "1           139 2023-02-09 19:41:43+00:00   Purina   \n",
       "2           140 2023-02-09 16:09:53+00:00   Purina   \n",
       "\n",
       "                                                                                                 Full_Tweets  \\\n",
       "0   thank you for reaching out. we're sorry that we are experiencing some technical difficulties and our ded   \n",
       "1       thank you for reaching out. we're sorry that we are experiencing some technical difficulties and our   \n",
       "2         thank you for reaching out to us. when you have a chance, please send us a private message with th   \n",
       "\n",
       "               Tweet_Links         at_word  \n",
       "0  https://t.co/k5ncW6PGIU       lhartness  \n",
       "1  https://t.co/tABQff7epw    fireshadowed  \n",
       "2  https://t.co/GMsyUvy5Oq  BonnieblueBlue  "
      ]
     },
     "execution_count": 218,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_new.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "id": "9d887dd7-63a9-4421-9f1e-dc562303c2d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now remove punctuation\n",
    "df_new['Full_Tweets'] = df_new['Full_Tweets'].apply(lambda x: re.sub(\"[^a-z0-9]\",\" \", x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "id": "9560a7f8-3bd0-4419-9ba2-2754e7ed56f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tweet_Length</th>\n",
       "      <th>Tweet_Date</th>\n",
       "      <th>UserName</th>\n",
       "      <th>Full_Tweets</th>\n",
       "      <th>Tweet_Links</th>\n",
       "      <th>at_word</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>140</td>\n",
       "      <td>2023-02-09 19:42:43+00:00</td>\n",
       "      <td>Purina</td>\n",
       "      <td>thank you for reaching out  we re sorry that we are experiencing some technical difficulties and our ded</td>\n",
       "      <td>https://t.co/k5ncW6PGIU</td>\n",
       "      <td>lhartness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>139</td>\n",
       "      <td>2023-02-09 19:41:43+00:00</td>\n",
       "      <td>Purina</td>\n",
       "      <td>thank you for reaching out  we re sorry that we are experiencing some technical difficulties and our</td>\n",
       "      <td>https://t.co/tABQff7epw</td>\n",
       "      <td>fireshadowed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>140</td>\n",
       "      <td>2023-02-09 16:09:53+00:00</td>\n",
       "      <td>Purina</td>\n",
       "      <td>thank you for reaching out to us  when you have a chance  please send us a private message with th</td>\n",
       "      <td>https://t.co/GMsyUvy5Oq</td>\n",
       "      <td>BonnieblueBlue</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>144</td>\n",
       "      <td>2023-02-09 05:00:15+00:00</td>\n",
       "      <td>Purina</td>\n",
       "      <td>thanks for reaching out about alpo come   get it  we are sorry to share that while most sizes have been</td>\n",
       "      <td>https://t.co/VsPUdZPWfP</td>\n",
       "      <td>waffletower</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>94</td>\n",
       "      <td>2023-02-08 20:44:37+00:00</td>\n",
       "      <td>Purina</td>\n",
       "      <td>we can t keep our tails from wagging in anticipation of the  purinapetparade</td>\n",
       "      <td>httpNone</td>\n",
       "      <td>OpenDoorAnimals</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Tweet_Length                Tweet_Date UserName  \\\n",
       "0           140 2023-02-09 19:42:43+00:00   Purina   \n",
       "1           139 2023-02-09 19:41:43+00:00   Purina   \n",
       "2           140 2023-02-09 16:09:53+00:00   Purina   \n",
       "3           144 2023-02-09 05:00:15+00:00   Purina   \n",
       "4            94 2023-02-08 20:44:37+00:00   Purina   \n",
       "\n",
       "                                                                                                 Full_Tweets  \\\n",
       "0   thank you for reaching out  we re sorry that we are experiencing some technical difficulties and our ded   \n",
       "1       thank you for reaching out  we re sorry that we are experiencing some technical difficulties and our   \n",
       "2         thank you for reaching out to us  when you have a chance  please send us a private message with th   \n",
       "3    thanks for reaching out about alpo come   get it  we are sorry to share that while most sizes have been   \n",
       "4                              we can t keep our tails from wagging in anticipation of the  purinapetparade    \n",
       "\n",
       "               Tweet_Links          at_word  \n",
       "0  https://t.co/k5ncW6PGIU        lhartness  \n",
       "1  https://t.co/tABQff7epw     fireshadowed  \n",
       "2  https://t.co/GMsyUvy5Oq   BonnieblueBlue  \n",
       "3  https://t.co/VsPUdZPWfP      waffletower  \n",
       "4                 httpNone  OpenDoorAnimals  "
      ]
     },
     "execution_count": 220,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_new.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "id": "c4017556-1ed3-438a-b19b-cba350d1efe0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                   254\n",
       "swagmastarpaul      11\n",
       "BengalsMeggy         9\n",
       "reallylittlecat      5\n",
       "fukkinnobody         5\n",
       "                  ... \n",
       "DonaldBestCA         1\n",
       "StxxApparel          1\n",
       "SAMUELUSA2           1\n",
       "EmmaPrive            1\n",
       "RalfusJ              1\n",
       "Name: at_word, Length: 443, dtype: int64"
      ]
     },
     "execution_count": 221,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_new['at_word'].value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "id": "bef57802-5715-4e82-a3ed-e33f429b819d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    }
   ],
   "source": [
    "def count_at(mention):\n",
    "    count = 0\n",
    "    for item in mention.split():\n",
    "        count += 1\n",
    "    return count\n",
    "\n",
    "test = \"kirk kate cleo\"\n",
    "\n",
    "print(count_at(test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "id": "278365a0-8d3d-4938-ba17-9451af75d2a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new['Mention_Count'] = df_new['at_word'].apply(count_at)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "id": "8e8caa53-631b-4de1-adb7-da4ead5af5df",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tweet_Length</th>\n",
       "      <th>Tweet_Date</th>\n",
       "      <th>UserName</th>\n",
       "      <th>Full_Tweets</th>\n",
       "      <th>Tweet_Links</th>\n",
       "      <th>at_word</th>\n",
       "      <th>Mention_Count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>96</td>\n",
       "      <td>2022-11-29 19:48:02+00:00</td>\n",
       "      <td>DiamondPetFood</td>\n",
       "      <td>sorry  i have plans   the plans    petting my dog   playing with my dog   cuddling with my dog</td>\n",
       "      <td>httpNone</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>95</td>\n",
       "      <td>2022-11-29 19:47:06+00:00</td>\n",
       "      <td>DiamondPetFood</td>\n",
       "      <td>hermes loves dates at the dog park  anybody else    corrinne k</td>\n",
       "      <td>https://t.co/DIAAi3VbUX</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>80</td>\n",
       "      <td>2022-11-28 21:45:06+00:00</td>\n",
       "      <td>DiamondPetFood</td>\n",
       "      <td>where did all of these cardboard boxes come from</td>\n",
       "      <td>https://t.co/Kr8AlRG8GD</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Tweet_Length                Tweet_Date        UserName  \\\n",
       "197            96 2022-11-29 19:48:02+00:00  DiamondPetFood   \n",
       "198            95 2022-11-29 19:47:06+00:00  DiamondPetFood   \n",
       "199            80 2022-11-28 21:45:06+00:00  DiamondPetFood   \n",
       "\n",
       "                                                                                         Full_Tweets  \\\n",
       "197   sorry  i have plans   the plans    petting my dog   playing with my dog   cuddling with my dog   \n",
       "198                                  hermes loves dates at the dog park  anybody else    corrinne k    \n",
       "199                                              where did all of these cardboard boxes come from      \n",
       "\n",
       "                 Tweet_Links at_word  Mention_Count  \n",
       "197                 httpNone                      0  \n",
       "198  https://t.co/DIAAi3VbUX                      0  \n",
       "199  https://t.co/Kr8AlRG8GD                      0  "
      ]
     },
     "execution_count": 224,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_new.tail(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "id": "15d35873-b343-47af-8228-76a93696c54f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    524\n",
       "0    254\n",
       "2     19\n",
       "3      1\n",
       "Name: Mention_Count, dtype: int64"
      ]
     },
     "execution_count": 225,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_new['Mention_Count'].value_counts()\n",
    "# so unbalanced but a difference amongst them"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54482069-f05d-4e78-888c-8529e4bb385c",
   "metadata": {},
   "source": [
    "Save the crafted dataframe as a CSV for the EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "id": "8af630ec-ab29-4024-8250-98abe7b208e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new.to_csv('SA_data_clean.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
